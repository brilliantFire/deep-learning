{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainy Weekend with Autoencoders\n",
    "I'm spending a rainy weekend learning about autoencoders using TensorFlow and Keras in Python. I'm particularly interested in one kind of autoencoder called a *variational autoencoder* (because I think it might be useful in my thesis project - more on that in another post) but before I get there, let's back up and nail down some basics...\n",
    "\n",
    "### *What is autoencoding?*\n",
    "Autoencoding is much like what it sounds in the sense that the input and 'output' are essentially the same. It's an algorithm for data compression where the functions for compression and decompression are *learned from the data*. The autoencoder learns a compressed representation of the inputs. It's considered more of a *semi-supervised* learning method as opposed to a truly *unsupervised* one since it's not entirely 'targetless'. Instead it learns the targets from the data itself.\n",
    "\n",
    "Despite all this talk of data compression, autoencoders aren't typically used for that purpose. In practice, you're much more likely to see them being used to preprocess data (as in denoising - think images but it doesn't have to be ;) ) or for dimensionality reduction. In fact, the hidden layers of simple autoencoders are doing something like principal component analysis (PCA), another method traditionally used for dimensionality reduction.\n",
    "\n",
    "### *Autoencoders*\n",
    "Generally autoencoders have three parts: an encoder, a decoder, and a 'loss' function that maps one to the other. For the simplest autoencoders - the sort that compress and then reconstruct the original inputs from the compressed representation - we can think of the 'loss' as describing the amount of information lost in the process of reconstruction. Typically when people are talking about autoencoders, they're talking about ones where the encoders and decoders are neural networks (in our case deep convnets). In training the autoencoder, we're optimizing the parameters of the neural networks to minimize the 'loss' (or distance) and we do that by stochastic gradient descent (yet another topic for another post). \n",
    "\n",
    "### *The Variational Variety*\n",
    "There's a bunch of different kinds of autoencoders but for this post I'm going to concentrate on one type called a *variational autoencoder*. Variational autoencoders (VAEs) don't learn to morph the data in and out of a compressed representation of itself like simple, 'vanilla' autoencoders. Instead, they learn the parameters of the probability distribution that the data came from. These types of autoencoders have much in common with latent factor analysis (if you know something about that). The encoder and decoder learn models that are in terms of underlying, *latent* variables. \n",
    "\n",
    "VAEs have received a lot of attention in recent years because of their *generative* ability. Since they learn about the distribution the inputs came from, we can sample from that distribution to generate novel data. As well see, VAEs can also be used to cluster data in useful ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Rebecca\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, Lambda, Reshape, Layer, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras import backend as K   # 'generic' backend so code works with either tensorflow or theano\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the data. I'm working with the MNIST data in the context of the [Digit Recognizer competition on Kaggle](https://www.kaggle.com/c/digit-recognizer/data). I've downloaded the data in csv format so here I'm setting a working directory and loading the data into pandas dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir('C:\\\\Users\\\\Rebecca\\\\Documents\\\\NU_MSPA\\\\python_work\\\\PREDICT_454\\\\MNIST') # laptop\n",
    "\n",
    "train_orig = pd.read_csv('data/train.csv')\n",
    "test_orig = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a 'label' column full of 'missing' to the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0  missing       0       0       0       0       0       0       0       0   \n",
       "1  missing       0       0       0       0       0       0       0       0   \n",
       "2  missing       0       0       0       0       0       0       0       0   \n",
       "3  missing       0       0       0       0       0       0       0       0   \n",
       "4  missing       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 'label' column in test dataset; rearrange so that columns are in the same order as in train\n",
    "test_orig['label'] = 'missing'\n",
    "testCols = test_orig.columns.tolist()\n",
    "testCols = testCols[-1:] + testCols[:-1]\n",
    "test = test_orig[testCols]\n",
    "\n",
    "np.random.seed(555)\n",
    "train_split = np.random.rand(len(train_orig)) < 0.1\n",
    "train = train_orig[train_split]\n",
    "valid = train_orig[~train_split]\n",
    "\n",
    "train = train_orig\n",
    "# free up some space and delete train and test\n",
    "del train_orig, test_orig\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train, valid, and test sets into X's and Y's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['label'], axis = 1)\n",
    "X_valid = valid.drop(['label'], axis = 1)\n",
    "X_test = test.drop(['label'], axis = 1)\n",
    "\n",
    "y_train = train['label']\n",
    "y_valid = valid['label']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize some of the images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR0TWYeIjIusw8RGRdf4fn3eTcDJJkfUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d62d5f07b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_viz = X_train.values.reshape(-1,28,28,1)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train_viz[13][:,:,0])\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train_viz[69][:,:,0])\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train_viz[237][:,:,0])\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train_viz[420][:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our variational autoencoder requires three parts:  \n",
    "\n",
    "##### 1. An encoder network that learns the parameters (mean and variance) of the underlying latent distribution  \n",
    "This encoder is a CNN with 4 conv2D layers. You'll notice it has two output layers, one for the latent distribution mean (z_mu) and the other for its variance (z_log_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras' has no attribute 'Input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-27cb8747ebfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Input the image (28x28 nodes)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0minput_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Network architecture is [Conv2D -> relu]*4 ->\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras' has no attribute 'Input'"
     ]
    }
   ],
   "source": [
    "img_shape = (28, 28, 1)  # for MNIST\n",
    "batch_size = 16\n",
    "latent_dim = 2  # these are the mean and the variance of the latent distribution\n",
    "\n",
    "# Input the image (28x28 nodes)\n",
    "input_img = Input(shape=img_shape)\n",
    "\n",
    "# Network architecture is [Conv2D -> relu]*4 -> \n",
    "x = Conv2D(32, 3, padding='same', activation='relu')(input_img)\n",
    "x = Conv2D(64, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
    "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "shape_before_flattening = K.int_shape(x)    # Required later when decoding\n",
    "\n",
    "# Flatten -> Dense ->\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Out1: z_mu\n",
    "z_mu = Dense(latent_dim)(x)\n",
    "\n",
    "# Out2: z_log_sigma\n",
    "z_log_sigma = Dense(latent_dim)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. A means of randomly sampling a point from that distribution  \n",
    "Here we make a function that does the sampling from the latent distribution described by z_mu and z_log_sigma. Because compling the model in Keras requires that everything in our VAE be a layer object, we wrap the sampling function in a Lambda layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling function\n",
    "def sampling(args):\n",
    "    z_mu, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mu)[0], latent_dim),\n",
    "                              mean=0., stddev=1.)\n",
    "    return z_mu + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "# Turn into layer object\n",
    "z = Lambda(sampling)([z_mu, z_log_sigma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. A decoder network to map that point back into reconstructed image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer takes in the vector z sampled from the latent distribution\n",
    "decoder_input = Input(K.int_shape(z)[1:])\n",
    "\n",
    "# Dense layer expands input layer to the same number of pixels as before the encoder flatten step\n",
    "x = Dense(np.prod(shape_before_flattening[1:]), activation='relu')(decoder_input)\n",
    "\n",
    "# Reshape into same shape as before the encoder flatten step\n",
    "x = Reshape(shape_before_flattening[1:])(x)\n",
    "\n",
    "# Reverse the encoder stack of conv2D layers\n",
    "x = Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
    "x = Conv2D(1, 3, padding='same', activation='sigmoid')(x)\n",
    "\n",
    "# Decoder model statement\n",
    "decoder = Model(decoder_input, x)\n",
    "\n",
    "# Apply decoder to latent distribution sample z\n",
    "z_decoded = decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VAE is trained using two loss functions:  \n",
    "1. 'Reconstruction loss' - This is the cross-entropy describing the errors between the samples from the latent distribution and the original inputs.  \n",
    "2. The Kullback-Liebler divergence between the latent distribution and the prior.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomVariationalLayer(keras.layers.Layer):\n",
    "\n",
    "    def vae_loss(self, x, z_decoded):\n",
    "        x = K.flatten(x)\n",
    "        z_decoded = K.flatten(z_decoded)\n",
    "        # Reconstruction loss\n",
    "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "        # KL divergence\n",
    "        kl_loss = -5e-4 * K.mean(1 + z_log_sigma - K.square(z_mu) - K.exp(z_log_sigma), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)  \n",
    "    \n",
    "    # This subprocess adds our custom loss to the model\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        z_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, z_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        return x\n",
    "\n",
    "# We call our custom layer on the input and the decoded output,\n",
    "# to obtain the final model output.\n",
    "y = CustomVariationalLayer()([input_img, z_decoded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the KL divergence acts as a regularization term. Now we instantiate the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model statement\n",
    "vae = Model(inputs=input_img, outputs=y)\n",
    "vae.compile(optimizer='rmsprop', loss=None)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(x=X_train, y=None,\n",
    "        shuffle=True,\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_valid, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_encoded = encoder.predict(X_valid, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_valid_encoded[:, 0], x_valid_encoded[:, 1], c=y_valid)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
